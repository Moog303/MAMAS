{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import konlpy\n",
    "import fasttext\n",
    "import re\n",
    "import h5py\n",
    "\n",
    "import sys, os \n",
    "from random import shuffle\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer, one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import MaxPooling1D, Embedding, Dense, Concatenate, Input, Reshape, Bidirectional, LSTM, Flatten, Dropout, Conv1D, Conv2D, MaxPooling2D, GRU, TimeDistributed\n",
    "from keras.models import Model, Sequential, model_from_json\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import optimizers\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdata = pd.read_csv('./ratings.txt', sep='\\t', dtype='unicode')\n",
    "testdata = pd.read_csv('./ratings_test.txt', sep='\\t', dtype='unicode')\n",
    "traindata = pd.read_csv('./ratings_train.txt', sep='\\t', dtype='unicode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = list(traindata.document)\n",
    "ytrain = list(traindata.label)\n",
    "\n",
    "xtest = list(testdata.document)\n",
    "ytest = list(testdata.label)\n",
    "\n",
    "vecdata = list(rawdata.document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = np.array(xtrain, dtype='str')\n",
    "xtest = np.array(xtest, dtype='str')\n",
    "vecdata = np.array(vecdata, dtype='str')\n",
    "\n",
    "ytrain = np.array(ytrain, dtype=int)\n",
    "ytest = np.array(ytest, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtestjia = []\n",
    "f = open(\"./diningdata.txt\", 'r')\n",
    "lines = f.readlines()\n",
    "for line in lines:\n",
    "    xtestjia.append(line)\n",
    "f.close()\n",
    "\n",
    "xtestjun = []\n",
    "f2 = open(\"./juntestnew.txt\", 'r')\n",
    "lines = f2.readlines()\n",
    "for line in lines:\n",
    "    xtestjun.append(line)\n",
    "f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "밥이랑 같이 먹어\t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(xtestjun[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xtestjia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Nouns and Verbs Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def morphs_process(lines, tagger):\n",
    "    sentences = []\n",
    "    for line in lines:\n",
    "        sentence = []\n",
    "        pos = tagger.pos(line)\n",
    "        for pair in pos:\n",
    "            if (pair[1] in ['NNG','NNB'\n",
    "                            ,'NNBC','NR'\n",
    "                            ,'VV','VA','VX'\n",
    "                            ,'VCP','VCN','MM'\n",
    "                            ,'MAG', 'MAJ', 'IC', 'XR']) :\n",
    "                morpheme = pair[0]\n",
    "                sentence.append(morpheme)\n",
    "            else:\n",
    "                pass\n",
    "        sentences.append(sentence)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenExport(tokens, filename):\n",
    "    f = open(filename, 'w')\n",
    "    f.write('\\n')\n",
    "    for line in tokens:\n",
    "        f = open(filename, 'a')\n",
    "        f.writelines(' '.join(line))\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "mec = konlpy.tag.Mecab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xdata = morphs_process(vecdata, mec)\n",
    "Xtrain = morphs_process(xtrain, mec)\n",
    "Xtest = morphs_process(xtest, mec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtestjia = morphs_process(xtestjia, mec)\n",
    "Xtestjun = morphs_process(xtestjun, mec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121\n",
      "107\n"
     ]
    }
   ],
   "source": [
    "print(len(Xtestjia))\n",
    "print(len(Xtestjun))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xdata = Xdata + Xtestjia + Xtestjun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenExport(Xdata, 'tokens_new.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dataForVec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Vector Model\n",
    "### FT model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ftmodelmake(data, model, lr = 0.1, dim = 200, ws = 5, min_count = 10):\n",
    "    model = fasttext.skipgram(data, model, lr = lr, dim = dim, ws = ws, min_count = min_count)\n",
    "    print(len(model.words))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftmodel = ftmodelmake('tokens_new.txt', 'ftmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "ftModel = KeyedVectors.load_word2vec_format('ftmodel.vec')\n",
    "ftVocab= list(ftModel.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarTest(model, word):\n",
    "    ftsimilars = model.most_similar(positive=[word], topn=10)\n",
    "    for word, value in ftsimilars:\n",
    "        print(word, value)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"word '착' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-59e30af9385d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msimilarTest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mftModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'착'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-14635f55db80>\u001b[0m in \u001b[0;36msimilarTest\u001b[0;34m(model, word)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msimilarTest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mftsimilars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mftsimilars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    528\u001b[0m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m                     \u001b[0mall_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"word '착' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "similarTest(ftModel, '착')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ebdIdx(model, vocab_list):\n",
    "    embd_idx = {}\n",
    "\n",
    "    for w in vocab_list:\n",
    "        embd_idx[w] = model.__getitem__(w)\n",
    "\n",
    "    print(len(embd_idx))\n",
    "    return embd_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7237\n"
     ]
    }
   ],
   "source": [
    "embedding_idx = ebdIdx(ftModel, ftVocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Data Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSequence(text, MAX_FEATURES, word_index):\n",
    "    seq = []\n",
    "    for line in text:\n",
    "        lineseq = []\n",
    "        for i in range(len(line)):\n",
    "            if (word_index[line[i]] < MAX_FEATURES):\n",
    "                lineseq.append(word_index[line[i]])\n",
    "            else:\n",
    "                pass\n",
    "        seq.append(lineseq)\n",
    "    seq = pad_sequences(seq, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
    "    seq = np.array(seq)\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7237\n"
     ]
    }
   ],
   "source": [
    "MAX_FEATURES = len(embedding_idx)\n",
    "MAX_SEQUENCE_LENGTH = 60\n",
    "EMBEDDING_DIM = 200\n",
    "print(MAX_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([16534, 17392, 20432, 41435, 17396, 14564, 22567,  7864,  6183,\n",
       "         8272,  2817,  2460,  4087,  1705,  1539,  2774,  1249,  1202,\n",
       "         2106,  1001,  1009,  1861,   836,   678,   592,   815,   275,\n",
       "          200,   216,    54,    37,    51,    10,     5,     6,     2,\n",
       "            1,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     1]),\n",
       " array([ 0.  ,  1.32,  2.64,  3.96,  5.28,  6.6 ,  7.92,  9.24, 10.56,\n",
       "        11.88, 13.2 , 14.52, 15.84, 17.16, 18.48, 19.8 , 21.12, 22.44,\n",
       "        23.76, 25.08, 26.4 , 27.72, 29.04, 30.36, 31.68, 33.  , 34.32,\n",
       "        35.64, 36.96, 38.28, 39.6 , 40.92, 42.24, 43.56, 44.88, 46.2 ,\n",
       "        47.52, 48.84, 50.16, 51.48, 52.8 , 54.12, 55.44, 56.76, 58.08,\n",
       "        59.4 , 60.72, 62.04, 63.36, 64.68, 66.  ]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_FEATURES)\n",
    "tokenizer.fit_on_texts(Xdata)\n",
    "word_index = tokenizer.word_index\n",
    "sequences = tokenizer.texts_to_sequences(Xdata)\n",
    "seqlen = np.array([len(sequence) for sequence in sequences])\n",
    "np.histogram(seqlen, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = getSequence(Xtrain, MAX_FEATURES, word_index)\n",
    "x_test = getSequence(Xtest, MAX_FEATURES, word_index)\n",
    "y_train = to_categorical(np.asarray(ytrain))\n",
    "y_test = to_categorical(np.asarray(ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_testjia = getSequence(Xtestjia, MAX_FEATURES, word_index)\n",
    "x_testjun = getSequence(Xtestjun, MAX_FEATURES, word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(121, 60)\n",
      "(107, 60)\n",
      "['우와']\n"
     ]
    }
   ],
   "source": [
    "print(x_testjia.shape)\n",
    "print(x_testjun.shape)\n",
    "print(Xtestjia[68])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train tensor: (150000, 60)\n",
      "Shape of y_train tensor: (150000, 2)\n",
      "Shape of x_test tensor: (50000, 60)\n",
      "Shape of y_test tensor: (50000, 2)\n",
      "7236\n",
      "1.0\n",
      "[ 53 372  15 126 441   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0]\n",
      "[[4120 4120  183  292 3043   72   22    6    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [ 226 4120    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [ 300 1265    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [1051  710    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [2971 3043 4120  155  195  487 4120  293 4120  293 4120 3043 4120    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [3043 4120   21 1051  338    6   17 6811 4120 6811  191 1051  733   68\n",
      "   195  957  957 4120  183 1051  710    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [1051 4120 6811   39   57 6811 4120 2655  191  245  487   82 6811 6811\n",
      "  6811 6811 6811 6811 1370   68   39   57 6811  191   22    6    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [3295  407   54  183    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "print('Shape of x_train tensor:', x_train.shape)\n",
    "print('Shape of y_train tensor:', y_train.shape)\n",
    "print('Shape of x_test tensor:', x_test.shape)\n",
    "print('Shape of y_test tensor:', y_test.shape)\n",
    "print(np.amax(x_train))\n",
    "print(np.amax(y_train))\n",
    "print(x_train[0])\n",
    "print(x_testjia[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing embedding matrix...\n"
     ]
    }
   ],
   "source": [
    "print('Preparing embedding matrix...')\n",
    "\n",
    "num_words = min(MAX_FEATURES, len(ftVocab) + 1) #unknown word 때문에 +1\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i >= MAX_FEATURES:\n",
    "        continue\n",
    "    embedding_vector = embedding_idx.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "embedding_layer = Embedding(num_words,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix], \n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7237, 200)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Build, Train & Evaluate\n",
    "### Common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path where all models are saved\n",
    "BASE_PATH = './model_180816/'\n",
    "if not os.path.exists(BASE_PATH):\n",
    "    os.mkdir(BASE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_checkpoint(model_name):\n",
    "    MODEL_PATH = os.path.join(BASE_PATH, model_name)\n",
    "    if not os.path.exists(MODEL_PATH):\n",
    "        os.mkdir(MODEL_PATH)\n",
    "    \n",
    "    return ModelCheckpoint(filepath=os.path.join(MODEL_PATH, 'val_loss-{val_loss:.4f}.hdf5'),\n",
    "                           monitor='val_loss',\n",
    "                           verbose=1,\n",
    "                           save_best_only=True)\n",
    "\n",
    "def create_checkpoint2(model_name):\n",
    "    MODEL_PATH = os.path.join(BASE_PATH, model_name)\n",
    "    if not os.path.exists(MODEL_PATH):\n",
    "        os.mkdir(MODEL_PATH)\n",
    "    \n",
    "    return ModelCheckpoint(filepath=os.path.join(MODEL_PATH, 'val_acc-{val_acc:.4f}.hdf5'),\n",
    "                           monitor='val_acc',\n",
    "                           verbose=1,\n",
    "                           save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "max_epochs = 100\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                               patience=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNNModel(num_filters = 64, drop =0.7):\n",
    "    filter_sizes = [3,4,5]\n",
    "\n",
    "    sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "    embedded_sequences = embedding_layer(sequence_input)\n",
    "    reshape = Reshape((MAX_SEQUENCE_LENGTH,EMBEDDING_DIM,1))(embedded_sequences)\n",
    "\n",
    "    conv_0 = Conv2D(num_filters, \n",
    "                    kernel_size=(filter_sizes[0], EMBEDDING_DIM), \n",
    "                    padding='valid', \n",
    "                    kernel_initializer='normal', \n",
    "                    activation='relu')(reshape)\n",
    "    conv_1 = Conv2D(num_filters, \n",
    "                    kernel_size=(filter_sizes[1], EMBEDDING_DIM), \n",
    "                    padding='valid', \n",
    "                    kernel_initializer='normal', \n",
    "                    activation='relu')(reshape)\n",
    "    conv_2 = Conv2D(num_filters, \n",
    "                    kernel_size=(filter_sizes[2], EMBEDDING_DIM), \n",
    "                    padding='valid', \n",
    "                    kernel_initializer='normal', \n",
    "                    activation='relu')(reshape)\n",
    "   \n",
    "\n",
    "\n",
    "    maxpool_0 = MaxPooling2D(pool_size=(MAX_SEQUENCE_LENGTH - filter_sizes[0] + 1, 1), \n",
    "                             strides=(1,1), \n",
    "                             padding='valid')(conv_0)\n",
    "    maxpool_1 = MaxPooling2D(pool_size=(MAX_SEQUENCE_LENGTH - filter_sizes[1] + 1, 1), \n",
    "                             strides=(1,1), \n",
    "                             padding='valid')(conv_1)\n",
    "    maxpool_2 = MaxPooling2D(pool_size=(MAX_SEQUENCE_LENGTH - filter_sizes[2] + 1, 1), \n",
    "                             strides=(1,1), \n",
    "                             padding='valid')(conv_2)\n",
    "\n",
    "\n",
    "    concatenated_tensor = Concatenate(axis=1)([maxpool_0, maxpool_1, maxpool_2])\n",
    "    flatten = Flatten()(concatenated_tensor)\n",
    "    dropout = Dropout(drop)(flatten)\n",
    "    preds = Dense(2, activation='sigmoid')(dropout)\n",
    "\n",
    "    model = Model(sequence_input, preds)\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    checkloss = create_checkpoint('CNN') \n",
    "    checkacc = create_checkpoint2('CNN')\n",
    "    \n",
    "    print('Training...')\n",
    "    history = model.fit(x_train, y_train, \n",
    "              batch_size=batch_size, \n",
    "              epochs=max_epochs, \n",
    "              verbose=1, \n",
    "              shuffle=True,\n",
    "              callbacks=[checkloss, checkacc, early_stopping], \n",
    "              validation_split=0.15) \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 60)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 60, 200)      1447400     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 60, 200, 1)   0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 58, 1, 64)    38464       reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 57, 1, 64)    51264       reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 56, 1, 64)    64064       reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 1, 1, 64)     0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 1, 1, 64)     0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 1, 1, 64)     0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 3, 1, 64)     0           max_pooling2d_1[0][0]            \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 192)          0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 192)          0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            386         dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,601,578\n",
      "Trainable params: 154,178\n",
      "Non-trainable params: 1,447,400\n",
      "__________________________________________________________________________________________________\n",
      "Training...\n",
      "Train on 127500 samples, validate on 22500 samples\n",
      "Epoch 1/100\n",
      "127500/127500 [==============================] - 97s 761us/step - loss: 0.4412 - acc: 0.7933 - val_loss: 0.4071 - val_acc: 0.8099\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.40708, saving model to ./model_180816/CNN/val_loss-0.4071.hdf5\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.80989, saving model to ./model_180816/CNN/val_acc-0.8099.hdf5\n",
      "Epoch 2/100\n",
      "127500/127500 [==============================] - 90s 705us/step - loss: 0.4101 - acc: 0.8112 - val_loss: 0.3968 - val_acc: 0.8153\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.40708 to 0.39678, saving model to ./model_180816/CNN/val_loss-0.3968.hdf5\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.80989 to 0.81531, saving model to ./model_180816/CNN/val_acc-0.8153.hdf5\n",
      "Epoch 3/100\n",
      "127500/127500 [==============================] - 95s 748us/step - loss: 0.3977 - acc: 0.8173 - val_loss: 0.3922 - val_acc: 0.8176\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.39678 to 0.39223, saving model to ./model_180816/CNN/val_loss-0.3922.hdf5\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.81531 to 0.81762, saving model to ./model_180816/CNN/val_acc-0.8176.hdf5\n",
      "Epoch 4/100\n",
      "127500/127500 [==============================] - 91s 712us/step - loss: 0.3879 - acc: 0.8228 - val_loss: 0.3878 - val_acc: 0.8200\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.39223 to 0.38783, saving model to ./model_180816/CNN/val_loss-0.3878.hdf5\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.81762 to 0.82004, saving model to ./model_180816/CNN/val_acc-0.8200.hdf5\n",
      "Epoch 5/100\n",
      "127500/127500 [==============================] - 93s 731us/step - loss: 0.3805 - acc: 0.8271 - val_loss: 0.3863 - val_acc: 0.8206\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.38783 to 0.38631, saving model to ./model_180816/CNN/val_loss-0.3863.hdf5\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.82004 to 0.82062, saving model to ./model_180816/CNN/val_acc-0.8206.hdf5\n",
      "Epoch 6/100\n",
      "127500/127500 [==============================] - 90s 704us/step - loss: 0.3727 - acc: 0.8313 - val_loss: 0.3870 - val_acc: 0.8199\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.38631\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.82062\n",
      "Epoch 7/100\n",
      "127500/127500 [==============================] - 99s 780us/step - loss: 0.3682 - acc: 0.8326 - val_loss: 0.3855 - val_acc: 0.8229\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.38631 to 0.38554, saving model to ./model_180816/CNN/val_loss-0.3855.hdf5\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.82062 to 0.82291, saving model to ./model_180816/CNN/val_acc-0.8229.hdf5\n",
      "Epoch 8/100\n",
      "127500/127500 [==============================] - 94s 740us/step - loss: 0.3617 - acc: 0.8377 - val_loss: 0.3845 - val_acc: 0.8236\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.38554 to 0.38453, saving model to ./model_180816/CNN/val_loss-0.3845.hdf5\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.82291 to 0.82364, saving model to ./model_180816/CNN/val_acc-0.8236.hdf5\n",
      "Epoch 9/100\n",
      "127500/127500 [==============================] - 88s 688us/step - loss: 0.3573 - acc: 0.8390 - val_loss: 0.3854 - val_acc: 0.8216\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.38453\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.82364\n",
      "Epoch 10/100\n",
      "127500/127500 [==============================] - 89s 700us/step - loss: 0.3517 - acc: 0.8407 - val_loss: 0.3834 - val_acc: 0.8249\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.38453 to 0.38339, saving model to ./model_180816/CNN/val_loss-0.3834.hdf5\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.82364 to 0.82489, saving model to ./model_180816/CNN/val_acc-0.8249.hdf5\n",
      "Epoch 11/100\n",
      "127500/127500 [==============================] - 89s 701us/step - loss: 0.3478 - acc: 0.8428 - val_loss: 0.3851 - val_acc: 0.8237\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.38339\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.82489\n",
      "Epoch 12/100\n",
      "127500/127500 [==============================] - 87s 682us/step - loss: 0.3441 - acc: 0.8455 - val_loss: 0.3834 - val_acc: 0.8256\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.38339 to 0.38338, saving model to ./model_180816/CNN/val_loss-0.3834.hdf5\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.82489 to 0.82560, saving model to ./model_180816/CNN/val_acc-0.8256.hdf5\n",
      "Epoch 13/100\n",
      "127500/127500 [==============================] - 86s 678us/step - loss: 0.3398 - acc: 0.8472 - val_loss: 0.3881 - val_acc: 0.8243\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.38338\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.82560\n",
      "Epoch 14/100\n",
      "127500/127500 [==============================] - 86s 672us/step - loss: 0.3359 - acc: 0.8494 - val_loss: 0.3872 - val_acc: 0.8232\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.38338\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.82560\n",
      "Epoch 15/100\n",
      "127500/127500 [==============================] - 85s 668us/step - loss: 0.3327 - acc: 0.8515 - val_loss: 0.3880 - val_acc: 0.8245\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.38338\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.82560\n",
      "Epoch 16/100\n",
      "127500/127500 [==============================] - 85s 668us/step - loss: 0.3296 - acc: 0.8517 - val_loss: 0.3924 - val_acc: 0.8224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00016: val_loss did not improve from 0.38338\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.82560\n",
      "Epoch 17/100\n",
      "127500/127500 [==============================] - 85s 663us/step - loss: 0.3276 - acc: 0.8532 - val_loss: 0.3908 - val_acc: 0.8233\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.38338\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.82560\n",
      "Epoch 18/100\n",
      "127500/127500 [==============================] - 85s 667us/step - loss: 0.3230 - acc: 0.8564 - val_loss: 0.3934 - val_acc: 0.8244\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.38338\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.82560\n",
      "Epoch 19/100\n",
      "127500/127500 [==============================] - 85s 666us/step - loss: 0.3216 - acc: 0.8567 - val_loss: 0.3945 - val_acc: 0.8219\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.38338\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.82560\n",
      "Epoch 20/100\n",
      "127500/127500 [==============================] - 85s 666us/step - loss: 0.3183 - acc: 0.8573 - val_loss: 0.3954 - val_acc: 0.8244\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.38338\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.82560\n",
      "Epoch 21/100\n",
      "127500/127500 [==============================] - 85s 665us/step - loss: 0.3154 - acc: 0.8590 - val_loss: 0.3969 - val_acc: 0.8236\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.38338\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.82560\n",
      "Epoch 22/100\n",
      "127500/127500 [==============================] - 85s 664us/step - loss: 0.3145 - acc: 0.8586 - val_loss: 0.3975 - val_acc: 0.8244\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.38338\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.82560\n"
     ]
    }
   ],
   "source": [
    "cnn = CNNModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_train(history):\n",
    "    fig, loss_ax = plt.subplots(figsize=(6,6))\n",
    "    acc_ax = loss_ax.twinx()\n",
    "\n",
    "    loss_ax.plot(history.history['loss'], 'y', label='train loss')\n",
    "    loss_ax.plot(history.history['val_loss'], 'r', label='val loss')\n",
    "    loss_ax.set_ylim([0.0, 3.0])\n",
    "\n",
    "    acc_ax.plot(history.history['acc'], 'b', label='train acc')\n",
    "    acc_ax.plot(history.history['val_acc'], 'g', label='val acc')\n",
    "    acc_ax.set_ylim([0.0, 1.1])\n",
    "\n",
    "    loss_ax.set_xlabel('epoch')\n",
    "    loss_ax.set_ylabel('loss')\n",
    "    acc_ax.set_ylabel('accuray')\n",
    "\n",
    "    loss_ax.legend(loc='upper left')\n",
    "    acc_ax.legend(loc='lower left')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def test_summary(model, weight_path):\n",
    "    plot_train(model[1])\n",
    "    model[0].load_weights(weight_path)\n",
    "    loss, acc = model[0].evaluate(x_test, y_test, batch_size=batch_size)\n",
    "    print('----- Evaluation loss and metrics -----')\n",
    "    print('Test loss:', loss)\n",
    "    print('Test accuracy:', acc)\n",
    "    \n",
    "def saveModel(model, name):\n",
    "    model_json = model[0].to_json()\n",
    "    with open(name, \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "\n",
    "def loadModel(modelfile, weightfile):\n",
    "    json_file = open(modelfile, 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    loaded_model.load_weights(weightfile)\n",
    "    loaded_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 10s 202us/step\n",
      "----- Evaluation loss and metrics -----\n",
      "Test loss: 0.3854660088443756\n",
      "Test accuracy: 0.82528\n"
     ]
    }
   ],
   "source": [
    "test_summary(cnn,'./model_180816/CNN/val_loss-0.3834.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveModel(cnn, 'cnn-0.825.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnnbes = loadModel('./cnn-0.825.json','./model_180816/CNN/val_loss-0.3834.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 10s 193us/step\n",
      "----- Evaluation loss and metrics -----\n",
      "Test loss: 0.38546629009246824\n",
      "Test accuracy: 0.82528\n"
     ]
    }
   ],
   "source": [
    "loss, acc = cnnbes.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "print('----- Evaluation loss and metrics -----')\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_summary(distance, threshold, data):\n",
    "    pos = 0\n",
    "    neg = 0\n",
    "    for i in distance:\n",
    "        if i >= threshold:\n",
    "            pos += 1\n",
    "        else :\n",
    "            neg +=1\n",
    "            \n",
    "    print('전체 문장:',len(distance))\n",
    "    print('긍정 문장:', pos)\n",
    "    print('부정 문장:', neg)\n",
    "    print('긍정 비율:', pos/len(distance), end='\\n\\n') \n",
    "    \n",
    "    best = np.argmax(distance)\n",
    "    worst = np.argmin(distance)     \n",
    "\n",
    "    plt.hist(distance,bins=20,color='black')\n",
    "    plt.xlabel('distance')\n",
    "    plt.ylabel('frequency')\n",
    "    plt.show()\n",
    "    \n",
    "    print('가장 긍적적인 문장 top5: ', sorted(zip(list(distance), data), reverse=True)[:5], end='\\n\\n')\n",
    "    print('가장 부정적인 문장 top5: ', sorted(zip(list(distance), data), reverse=False)[:5], end='\\n\\n')\n",
    "    print('Gray Area: ',len(grayarea(distance, data, threshold*-1)), grayarea(distance, data, threshold*-1))\n",
    "    \n",
    "def distance(prob):\n",
    "    distance = []\n",
    "    for i in range(len(prob)):\n",
    "        tmp = prob[i][1] - prob[i][0]\n",
    "        distance.append(tmp)\n",
    "    distance = np.array(distance)\n",
    "    return distance\n",
    "\n",
    "def numeric_gradient(histogram):\n",
    "    grad = []\n",
    "    for i in range(len(histogram[0])-1):\n",
    "        grad.append(histogram[0][i+1] - histogram[0][i])\n",
    "    grad = np.array(grad)\n",
    "    return np.argmax(grad)+1\n",
    "\n",
    "def threshold(histogram):\n",
    "    return histogram[1][numeric_gradient(histogram)]\n",
    "\n",
    "def grayarea(distance, data, margin):\n",
    "    gray = []\n",
    "    for index, dist in enumerate(distance):\n",
    "        if dist >= threshold(jun_histogram) and dist < (threshold(jun_histogram) + margin):\n",
    "            gray.append(data[index])\n",
    "    return gray        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "testprobs_jia = cnnbes.predict(x_testjia, batch_size=batch_size, verbose=0, steps=None)\n",
    "testprobs_jun = cnnbes.predict(x_testjun, batch_size=batch_size, verbose=0, steps=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_jun = distance(testprobs_jun)\n",
    "dist_jia = distance(testprobs_jia)\n",
    "\n",
    "jun_histogram = np.histogram(dist_jun, bins=20)\n",
    "jia_histogram = np.histogram(dist_jia, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 문장: 107\n",
      "긍정 문장: 69\n",
      "부정 문장: 38\n",
      "긍정 비율: 0.6448598130841121\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가장 긍적적인 문장 top5:  [(0.99994135, '아빠도? 아빠 아. 아빠도 화이팅, 화이팅 화이팅 화이팅. \\n'), (0.9997122, '엉클도 화이팅 화이팅 화이팅 화이팅. 화이팅 화이팅 화이팅. 음, 이거 엄청 달다. \\n'), (0.999268, '손 말고 포크로. 화이팅. 준이 멋있다. 준이. 와, 멋있다. \\n'), (0.9986962, '또? 또 줘? 준이꺼, 준이꺼 먹어. 화이팅. 화이팅. 엄마가 치킨 갖다줄게. \\n'), (0.9981921, '너무 멋있다. 준이 최고. 최고. 최고.\\n')]\n",
      "\n",
      "가장 부정적인 문장 top5:  [(-0.99875754, '일어났으니까 엄마 이제 치워야겠다. 앉아. 앉아. 똑바로 앉으세요. 노. 노. 다시 먹어. 홍준. 누가 너 아까 그렇게 많이많이 넣으래 하나씩 넣는 거에요. 엄마 보세요. 하나씩 넣어. 하나씩만. 준이 이거 뱉으면 이제 끝이야. 알았어요? \\n'), (-0.9582926, '준이 똑바로 앉아. 앉아. 앉아. 앉으세요. 안 돼. 안 돼. 앉아. 앉아. No. \\n'), (-0.9231533, '준아 뱉으면 아니야, 뱉으면 엄마 이제 이거 치워버릴 거야. 그러니까 냠냠 꼭꼭 하고 꿀꺽해야 해. 꼭꼭. 맘마. \\n'), (-0.90837836, '어? 뱉지마. 뱉으면 안 돼. 뱉지마. 뱉으면 끝이야. 뱉으면 이거 다 치워버릴 거야. \\n'), (-0.89208364, '준이 밥 떠먹어 밥. 밥 떠먹어요 밥. \\n')]\n",
      "\n",
      "Gray Area:  32 ['고마워\\n', '밥이랑 같이 먹어\\t\\n', '이거? 이게 뭐지? 뭐야? \\n', '준이 고기 더 먹고 싶으면 말해. \\n', '아이 예뻐. \\n', '아빠 콜라 가지러 갔어요. \\n', '그거 빨리 치워야지.  \\n', '아빠도 먹을 거야. \\n', '엉클도 아빠도 다들 콕콕. \\n', '차가워 차가워. \\n', '냠냠 꼭꼭. \\n', '알약. \\n', '여기서 해야지 여기서. 여기여기. \\n', '내가 해줄게. \\n', '냠냠 꼭꼭 하고 꿀꺽해 꿀꺽. \\n', '그러면 빨간색 한번 먹어볼까? \\n', '옳지 아이 예뻐. \\n', '아빠, 아빠도 브로콜리 드세요~ \\n', '아빠도 엉클도 알리아도. \\n', '어때. 사탕. 같이 고민을 해봐야겠다.\\n', '시금치야. 시금치. 준이 시금치도 먹어야 돼요. \\n', '치킨 더 먹고 싶으면 말해. \\n', '준아 이거 감자야. \\n', '감자 먹어야 돼. \\n', '응 같이. 어, 준아. 준이가 감자 안 먹어요. \\n', '준이 앉아. 아빠꺼는. 너무 많다. 많다. 어이구. 아. 준이가 먹어.\\n', '어, 아냐. 뱉지마. 다시 먹어. \\n', '물 마셔 물. 베이비 치킨. 베비이 치킨. 베이비. 베이비. 베이비만 먹는 거야. 뼈. \\n', '잘 먹었다. Good job. \\n', '뼈밖에 없어. 뼈야. 지지. 이거? 이거. \\n', '브로콜리랑 같이 먹어야 예뻐요. \\n', '이거. 이거. 엄마 파프리카 먹는다. \\n']\n"
     ]
    }
   ],
   "source": [
    "predict_summary(dist_jun, threshold(jun_histogram), xtestjun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 문장: 121\n",
      "긍정 문장: 95\n",
      "부정 문장: 26\n",
      "긍정 비율: 0.7851239669421488\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가장 긍적적인 문장 top5:  [(0.84421796, '이제 조금밖에 안남았어 우리 빨리먹고 강아지를 보러 가야해 의사선생님 기다리잖아 의사선생님 보고 그 다음에 강아지 집에 얼른 가자\\n'), (0.79489636, '뽀로로 젓가락으로, 왼손 젓가락으로 먹는날. 지아 완전 잘하죠?\\n'), (0.7857513, '지아가 혼자서 우와 다시 지아가 혼자서 혼자서 그렇지 그렇지 우와 밥도 한 젓가락\\n'), (0.71147335, '잘한다 잘한다 잘한다\\n'), (0.71147335, '잘한다 잘한다 잘한다\\n')]\n",
      "\n",
      "가장 부정적인 문장 top5:  [(-0.93987405, '이제 밥을 넣으면 끝 밥을 넣으면 성공 돌려 숟가락 돌려 돌려 더돌려\\n'), (-0.8981681, '밥을 넣으면 성공이야 간다 간다라간다 간다 간다 밥 간다\\n'), (-0.8767928, '지아야 아빠가 밥 국물에 적셔주세요 해서 국물에 적셨어 이것봐 국물\\n'), (-0.75710464, '국물 밥먹고 또 국물 먹자\\n'), (-0.72159225, '국물주세요 국물주세요\\n')]\n",
      "\n",
      "Gray Area:  44 ['그렇지 아유 이쁘다\\n', '지아야\\n', '지아야 떠봐. 숟가락질도 할 수 있어\\n', '양파도 한 입\\n', '으음\\n', '아삭아삭 맛있는데\\n', '지아 양파먹을 수 있지 않나?\\n', '여기있어요\\n', '네\\n', '네\\n', '지아 입 속으로 사라지는 마술 사라지는 마술 사라지는 마술\\n', '아빠도 한 입 먹을까\\n', '아빠도 한 입\\n', '아빠도 반찬 해다가 우거지를 한 젓가락 찝어서\\n', '응\\n', '파 잖아\\n', '아 파야 이거?\\n', '자 우거지\\n', '이거 괜찮은거지?\\n', '숟가락으로 할꺼야\\n', '양파 쏙\\n', '아삭아삭\\n', '엄마가 내려놓을게 지아가 해봐\\n', '놔봐\\n', '없어지는 마술\\n', '지아야 계란까지 올려줄게 엄마가\\n', '사라지는 마술\\n', '지아야 이것봐\\n', '밥이 밥이 지아야 나를 빨리 먹어\\n', '그러려면 빨리 먹어 사라지는 마술. 지아가 먹을래? 우와 사라지는 마술\\n', '아빠가 한 번 볼까?\\n', '없다\\n', '입 속으로 쏙 들어와라\\n', '마지막 피날레는 젓가락으로\\n', '맛있겠다\\n', '지아 지아\\n', '한꺼번에 하나씩만 요구하라고요\\n', '이지아\\n', '적셨네\\n', '지아 끝났네 지아 없다\\n', '지아 잘 먹었네\\n', '잘 먹었습니다\\n', '잘 먹었으면 어떻게 해야해\\n', '잘 먹었습니다 인사 해야지\\n']\n"
     ]
    }
   ],
   "source": [
    "predict_summary(dist_jia, threshold(jia_histogram), xtestjia)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
